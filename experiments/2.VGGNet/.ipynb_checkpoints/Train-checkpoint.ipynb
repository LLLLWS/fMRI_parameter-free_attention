{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Network.ipynb\n",
      "importing Jupyter notebook from HCPDataLoader.ipynb\n",
      "importing Jupyter notebook from ResultCalculator.ipynb\n",
      "importing Jupyter notebook from LoggerCreator.ipynb\n",
      "importing Jupyter notebook from EarlyStopping.ipynb\n"
     ]
    }
   ],
   "source": [
    "# VGG\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from Network import Network\n",
    "from HCPDataLoader import getHCPDataSet\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from ResultCalculator import resultCalculator\n",
    "from LoggerCreator import loggerCreator\n",
    "from EarlyStopping import EarlyStopping\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "os.system('rm -rf ./logs/*')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "logger = loggerCreator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCPDataListPath = './s2_con1_label.txt'\n",
    "HCPDataRootPath = '../../data/disk/'\n",
    "\n",
    "BATCHSIZE = 16\n",
    "LEARNINGRATE = 0.0001\n",
    "EPOCH = 50\n",
    "EXPERIMENTTIMES = 10\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 2644, Evaluation: 165, Test: 496\n"
     ]
    }
   ],
   "source": [
    "dataSet = getHCPDataSet(HCPDataRootPath, HCPDataListPath, evalRate=0.05, testRate=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeAcc(idx, loss, predict, trainLabel, writer, prefix=None, outputPath=None):\n",
    "    acc, result = resultCalculator(predict, trainLabel, prefix=prefix, outputPath=outputPath)\n",
    "    logger.info(\"{}: ({}) acc:{}%, loss:{}\".format(idx, prefix, acc, loss))\n",
    "    \n",
    "    writer.add_scalar('acc', acc, idx)\n",
    "    writer.add_scalar('loss', loss, idx)\n",
    "    \n",
    "    resultSum = result.sum(1)\n",
    "    for i in range(result.shape[0]):\n",
    "        writer.add_scalar('tasks/{}'.format(i), result[i][i]/resultSum[i] * 100, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAnEpoch(dataLoader, net, lossFunc):\n",
    "    loss = 0\n",
    "    predicts = None\n",
    "    labels = None\n",
    "    \n",
    "    net.eval()\n",
    "    for idx, (data, label) in enumerate(dataLoader):\n",
    "        labels = label if loss == 0 else np.hstack((labels, label))\n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "        predict = net(data)\n",
    "        \n",
    "        predicts = predict.cpu().detach().numpy() if loss == 0 else np.vstack((predicts, predict.cpu().detach().numpy()))\n",
    "        loss += lossFunc(predict, label).item()\n",
    "        \n",
    "        logger.info(\"Evaluationg, {}\".format(labels.shape[0]))\n",
    "    net.train()\n",
    "    return  predicts, labels, loss/labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNetwork(learningRate, BatchSize, experimentTimes = 0):\n",
    "    logger.info(\"--------------------------------------------------------------\")\n",
    "    logger.info(\"Network loading, learningRate: {}, BatchSize: {}, experimentTimes: {}\"\n",
    "                .format(learningRate, BatchSize, experimentTimes))\n",
    "    trainWriter = SummaryWriter('logs/train_{}_{}_{}/'\n",
    "                                .format(BatchSize, learningRate, experimentTimes))\n",
    "    evalWriter = SummaryWriter('logs/eval_{}_{}_{}/'\n",
    "                               .format(BatchSize, learningRate, experimentTimes))\n",
    "    testWriter = SummaryWriter('logs/test_{}_{}_{}/'\n",
    "                               .format(BatchSize, learningRate, experimentTimes))\n",
    "    \n",
    "    trainLoader = DataLoader(dataSet.trainDataSet, batch_size = BatchSize, num_workers=16, shuffle = True)\n",
    "    evalLoader = DataLoader(dataSet.evalDataSet, batch_size = BatchSize, num_workers=8, shuffle = True)\n",
    "    testLoader = DataLoader(dataSet.testDataSet, batch_size = BatchSize, num_workers=8, shuffle = True)\n",
    "    logger.info(\"DataLoader have been created!\")\n",
    "    \n",
    "    net = Network().cuda()\n",
    "    logger.info(\"Network have been established.\")\n",
    "\n",
    "    lossFunc = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LEARNINGRATE)\n",
    "    early_stopping = EarlyStopping(PATIENCE, verbose=True, experimentTimes=experimentTimes)\n",
    "    net.train()\n",
    "    logger.info(\"Train begining.\")\n",
    "    idx = 0\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        try:\n",
    "            for trainData, trainLabel in trainLoader:\n",
    "                idx += 1\n",
    "                trainData = trainData.cuda()\n",
    "                trainLabel = trainLabel.cuda()\n",
    "\n",
    "                predict = net(trainData)\n",
    "                loss = lossFunc(predict, trainLabel)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if idx % 5 == 0:\n",
    "                    writeAcc(idx, loss.item(), predict, trainLabel, trainWriter, 'train')\n",
    "\n",
    "                if idx % 50 == 0:\n",
    "                    logger.info(\"Evaluating!\")\n",
    "                    predicts, label, loss = runAnEpoch(evalLoader, net, lossFunc)\n",
    "                    writeAcc(idx, loss, predicts, label, evalWriter, 'eval', outputPath='./RESULT.md')\n",
    "\n",
    "                    early_stopping(loss, net)\n",
    "                    if early_stopping.early_stop:\n",
    "                        break\n",
    "\n",
    "        except Exception as exc:\n",
    "            logger.error(str(exc))\n",
    "            \n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "        \n",
    "    if early_stopping.early_stop:\n",
    "        logger.warning(\"Early stopping!\")\n",
    "        predicts, label, loss = runAnEpoch(testLoader, net, lossFunc)\n",
    "        writeAcc(idx, loss, predicts, label, testWriter, 'test', outputPath='./testRESULT.md')\n",
    "     \n",
    "    trainWriter.close()\n",
    "    evalWriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-04 18:51:46,303[line:2] - INFO: --------------------------------------------------------------\n",
      "2020-06-04 18:51:46,306[line:4] - INFO: Network loading, learningRate: 0.0001, BatchSize: 16, experimentTimes: 0\n",
      "2020-06-04 18:51:46,312[line:15] - INFO: DataLoader have been created!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for experimentTimes in range(EXPERIMENTTIMES):\n",
    "        trainNetwork(LEARNINGRATE, BATCHSIZE, experimentTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
